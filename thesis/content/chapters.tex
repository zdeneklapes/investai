%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}\label{ch:introduction}

% TODO: Purpose of RL
% TODO: Purpose of MDP
% TODO

% Overview of what this thesis is about
The stock market is a wide and quickly changing environment.
A lot of people are interested in it and a lot of people are trying to make money from it.
How to make money from it in the long or short term?
This thesis will focus on long-term investing, also called Portfolio Allocation.

% Main goal of this thesis and why AI
The goal is to do the right decision at the right time, which in the Stock market means, when and at what price we should buy this stock or another.
This is more complicated than it seems because we are emotionally
based, and not every person is able to make rational decisions.
Here come into play AI, which is able to make rational
decisions based only on the things it has learned.

% RL and MDP




You need to know how to invest and understand how companies work.
What the main business of the company is.
On what product or service the company is focused
and what is the stream of the companies' income.
Then you need
to follow simple rules, and you will be able to make money from the stock market e.q.\ as Warren Buffett did.
But in these thesis we wil focus on long term investing as Warren Buffett,
instead of short term investing as day traders.
Then we will focus on how to invest in the stock market and how to make money
from it using Reinforcement Learning and HMM\@.
Reinforcement Learning is a machine learning algorithm that is used to train agents to
make decisions in an environment.
These further decisions are based on the previous rewards and looses that the agent
gets from the environment.
The agent is trying to maximize the reward and minimize the looses.
This approach is very similar as people learn from their mistakes or successes.
This branch of machine learning is very popular in the field of robotics and autonomous driving,
it is also used in the field of video games, but in stock market it is not used very often,
at least this is not published in the scientific literature very often.
So I decided to use this approach in the stock market and see if it is possible to make money from it.
My goal is to evaluate, benchmarks and try to improve the current solutions of models
based on Reinforcement Learning and HMM in the stock market achieved by AI4Finance.
The goal is to make a model that will be able to make money from the stock market in a long term
and help in the decision-making process of the long term investor in creating, managing and evaluating
their portfolio of stocks.
In this thesis I will focus on training agent for stocks from US index S\&P 500.
The agent will be trained on the historical data, and he should be able to predict
what companies will be the most profitable and based on that the investor should be able
to invest into these companies.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Preliminaries
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Preliminaries}\label{ch:preliminaries}
In this~\cite{biblio}.


\section{Markov Processes}\label{sec:markov-processes}


\section{Markov Decision Process}\label{sec:markov-decision-process}
TODO

\subsection{Bellman Equation}\label{subsec:bellman-equation}
TODO

\subsection{Bellman Optimality Equation}\label{subsec:bellman-optimality-equation}
TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Exisiting Approaches
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Existing Approaches to Portfolio Allocation}\label{ch:existing-approaches-to-portfolio-allocation}
TODO


\section{Introduction}\label{sec:introduction}
TODO


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Reinforcement Learning
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Reinforcement Learning}\label{ch:reinforcement-learning}
TODO


\section{Classical Reinforcement Learning}\label{sec:classical-reinforcement-learning}
TODO


\section{Parts of Reinforcement Learning}\label{sec:parts-of-reinforcement-learning}
TODO


\section{Functionalities of Reinforcement Learning}\label{sec:functionalities-of-reinforcement-learning}
TODO


\section{Reinforcement Learning Algorithms}\label{sec:reinforcement-learning-algorithms2}
TODO


\section{Deep Reinforcement Learning}\label{sec:deep-reinforcement-learning}
TODO

\subsection{Exploration vs. Exploitation}\label{subsec:exploration-vs.-exploitation}
TODO


\section{Reinforcement Learning Algorithms}\label{sec:reinforcement-learning-algorithms}
TODO: Describe used RL Algorithms

\subsection{Deep Reinforcement Learning Algorithms}\label{subsec:deep-reinforcement-learning-algorithms}
TODO

\subsubsection{PPO}
TODO

\subsubsection{SAC}
TODO

\subsubsection{TD3}
TODO

\subsubsection{DDPG}
TODO


\section{Existing solutions}\label{sec:existing-solutions}
TODO


\section{Neural Networks}\label{sec:neural-networks}
TODO


\section{Used Frameworks}\label{sec:used-frameworks}
TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Environment
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Environment}\label{ch:environment}
TODO


\section{Stock Market Environment}\label{sec:stock-market-environment}
TODO

\subsection{Used Frameworks}\label{subsec:used-frameworks}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Data
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Data Engineering}\label{ch:data-engineering}
TODO


\section{Data Collection}\label{sec:data-collection}
TODO


\section{Data Preprocessing}\label{sec:data-preprocessing}
TODO

\subsection{Data Cleaning}\label{subsec:data-cleaning}
TODO


\section{Different kinds of Data}\label{sec:different-kinds-of-data}
TODO

\subsection{Fundamental Data}\label{subsec:fundamental-data}
TODO

\subsection{Market Data}\label{subsec:market-data}
TODO

\subsection{Analytics Data}\label{subsec:analytics-data}
TODO

\subsection{Alternative Data}\label{subsec:alternative-data}
TODO


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Getting Ready Agent
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Agent}\label{ch:agent}
TODO


\section{Training Agent}\label{sec:training-agent}
TODO


\section{Testing Agent}\label{sec:testing-agent}
TODO


\section{Benchmarks and Results}\label{sec:benchmarks-and-results}
TODO


\section{Backtesting}\label{sec:backtesting}
TODO


\section{Portfolio Performance}\label{sec:portfolio-performance}
TODO


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Contribution to Finrl-Meta
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Contribution to Finrl-Meta}\label{ch:contribution-to-finrl-meta}
TODO


\section{1}\label{sec:1}
TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Evaluation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Evaluation}\label{ch:evaluation}
TODO


\section{1}\label{sec:12}
TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Conclusion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Conclusion}\label{ch:conclusion}
TODO
