{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "##\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import enum\n",
    "from enum import Enum\n",
    "import matplotlib\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "##\n",
    "sys.path.append(\"./src/\")\n",
    "sys.path.append(\"./\")\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "##\n",
    "from finrl import config as finrl_config\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
    "from finrl.config import (\n",
    "    TEST_END_DATE,\n",
    "    TRAINED_MODEL_DIR,\n",
    ")\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "from finrl.plot import backtest_stats, convert_daily_return_to_pyfolio_ts, get_baseline\n",
    "\n",
    "##\n",
    "import yfinance as yf\n",
    "\n",
    "##\n",
    "from meta.data_processors.yahoofinance import Yahoofinance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def config():\n",
    "    # #\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)  # TODO: zipline problem\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    # os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # INFO, WARN are ignored and only ERROR messages will be printed\n",
    "\n",
    "    # #\n",
    "    matplotlib.use(\"Agg\")\n",
    "\n",
    "    # #\n",
    "    check_and_make_directories(\n",
    "        [\n",
    "            finrl_config.DATA_SAVE_DIR,\n",
    "            finrl_config.TRAINED_MODEL_DIR,\n",
    "            finrl_config.TENSORBOARD_LOG_DIR,\n",
    "            finrl_config.RESULTS_DIR,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "config()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "##\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyfolio import timeseries\n",
    "import tqdm\n",
    "\n",
    "##\n",
    "from rl.data import DataTechnicalAnalysis, DataFundamentalAnalysis, DataBase\n",
    "from common.utils import now_time\n",
    "from configuration.settings import ProjectDir"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def print_info(df: pd.DataFrame):\n",
    "    ##\n",
    "    print(f\"{df.shape=}\")\n",
    "    print(f\"Start date: {df['date'].iloc[0]}\")\n",
    "    print(f\"End date: {df['date'].iloc[-1]}\")\n",
    "    print(f\"Stocks: {df['tic'].unique().size}\")\n",
    "\n",
    "    ##\n",
    "    data_grouped_by_date = df.groupby(by=[\"date\"])\n",
    "    grouped_data_size = data_grouped_by_date.size()\n",
    "    if grouped_data_size.nunique() == 1:\n",
    "        print(f\"OK: All dates have same row count: {grouped_data_size.unique()}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Different size for each date: {grouped_data_size.unique()}\")\n",
    "\n",
    "\n",
    "def check_dir(_filename: Path):\n",
    "    dir = _filename.parent\n",
    "    if os.path.isdir(dir):\n",
    "        print(f\"OK: Dir exist for: {_filename}\")\n",
    "    else:\n",
    "        raise NotADirectoryError(f\"ERROR: Dir does not exist {dir}\")\n",
    "\n",
    "\n",
    "class FileType(Enum):\n",
    "    JSON = enum.auto\n",
    "    CSV = enum.auto\n",
    "\n",
    "\n",
    "def save_dataset(dataframe: pd.DataFrame, type: FileType, _filename: str):\n",
    "    print(f\"Saving data into: {_filename}\")\n",
    "    if type == FileType.JSON:\n",
    "        dataframe.to_json(_filename)\n",
    "    elif type == FileType.CSV:\n",
    "        dataframe.to_csv(_filename)\n",
    "    else:\n",
    "        raise ValueError(f\"type: FileType must be CSV or JSON.\")\n",
    "    print(f\"Data saved to json: {_filename}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "prj_dir = ProjectDir(root=Path(\"/Users/zlapik/my-drive-zlapik/0-todo/ai-investing\"))\n",
    "_TRAIN_DATA_START = \"2010-01-01\"\n",
    "_TRAIN_DATA_END = \"2021-12-31\"\n",
    "_TEST_DATA_START = \"2021-01-01\"\n",
    "_TEST_DATA_END = \"2021-12-31\"\n",
    "tickers = DOW_30_TICKER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
     ]
    }
   ],
   "source": [
    "print(tickers.__len__())\n",
    "print(tickers)\n",
    "from meta.data_processors.yahoofinance import Yahoofinance\n",
    "\n",
    "data_processor = Yahoofinance(\n",
    "    data_source=\"yahoofinance\", start_date=_TRAIN_DATA_START, end_date=_TEST_DATA_END, time_interval=\"1d\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (88283, 9)\n"
     ]
    }
   ],
   "source": [
    "data_processor.download_data(ticker_list=tickers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29 30]\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88283, 9)\n",
      "df.shape=(88283, 9)\n",
      "Start date: 2010-01-04\n",
      "End date: 2021-12-30\n",
      "Stocks: 30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Different size for each date: [29 30]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [10], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(data_processor\u001B[38;5;241m.\u001B[39mdataframe\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      2\u001B[0m data_processor\u001B[38;5;241m.\u001B[39mdataframe\u001B[38;5;241m.\u001B[39mhead()\n\u001B[0;32m----> 3\u001B[0m \u001B[43mprint_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_processor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataframe\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [4], line 14\u001B[0m, in \u001B[0;36mprint_info\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOK: All dates have same row count: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgrouped_data_size\u001B[38;5;241m.\u001B[39munique()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDifferent size for each date: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgrouped_data_size\u001B[38;5;241m.\u001B[39munique()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Different size for each date: [29 30]"
     ]
    }
   ],
   "source": [
    "print(data_processor.dataframe.shape)\n",
    "data_processor.dataframe.head()\n",
    "print_info(data_processor.dataframe)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2010-01-04    29\n",
      "2010-01-05    29\n",
      "2010-01-06    29\n",
      "2010-01-07    29\n",
      "2010-01-08    29\n",
      "              ..\n",
      "2021-12-23    30\n",
      "2021-12-27    30\n",
      "2021-12-28    30\n",
      "2021-12-29    30\n",
      "2021-12-30    30\n",
      "Length: 3020, dtype: int64\n",
      "[29 30]\n",
      "29 : 2317\n",
      "30 : 703\n"
     ]
    }
   ],
   "source": [
    "# df = data_processor.dataframe\n",
    "\n",
    "# for i in range(1):\n",
    "#     date1 = df['date'].unique()[-i]\n",
    "#     grouped_by_date = df.groupby(by=[\"date\"])\n",
    "#     grouped_by_date_size = grouped_by_date.size()\n",
    "#     bad_date = df[df['date'] == date1]\n",
    "#     print(bad_date.shape)\n",
    "\n",
    "\n",
    "# sizes = df.groupby('date')['date'].transform('size')\n",
    "# sizes\n",
    "# df.drop_duplicates(subset='date', keep='first')\n",
    "\n",
    "# bad_date2\n",
    "# print(bad_date['tic'].unique().size)\n",
    "# print(bad_date2['tic'].unique().size)\n",
    "\n",
    "# grouped_by_df = df.groupby(by=[\"date\"])\n",
    "# grouped_by_size = grouped_by_df.size()\n",
    "# # print(grouped_by_df)\n",
    "# print(grouped_by_size)\n",
    "# print(grouped_by_size.unique())\n",
    "# counts = pd.Series([])\n",
    "# for i in grouped_by_size.unique():\n",
    "#     occurences = (grouped_by_size == i).sum()\n",
    "#     counts = counts.append(pd.Series(occurences))\n",
    "#     print(f\"{i} : {occurences}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\n"
     ]
    }
   ],
   "source": [
    "def get_missing_tic(df: pd.DataFrame, date: str) -> list:\n",
    "    df_date = df[df[\"date\"] == date]\n",
    "    missing_tics: set = set(tickers).difference(set(df_date[\"tic\"].values))\n",
    "    missing_tics: list = list(missing_tics)\n",
    "    return [missing_tics]\n",
    "\n",
    "\n",
    "def get_previous_value(df: pd.DataFrame, date: str, missing_tic: str):\n",
    "    df_before_date_binary = df[\"date\"] < date\n",
    "    df_before_date = df[df_before_date_binary]\n",
    "    previous_value_of_missing_tic = df_before_date[\"tic\"] == missing_tic[0]\n",
    "    df_missing_tic_previous_value = df_before_date[previous_value_of_missing_tic]\n",
    "    if df_missing_tic_previous_value.empty:\n",
    "        return None\n",
    "    else:\n",
    "        return df_missing_tic_previous_value.iloc[-1]\n",
    "\n",
    "\n",
    "def get_following_value(df: pd.DataFrame, date: str, missing_tic: str):\n",
    "    df_before_date_binary = df[\"date\"] > date\n",
    "    df_before_date = df[df_before_date_binary]\n",
    "    previous_value_of_missing_tic_binary = df_before_date[\"tic\"] == missing_tic[0]\n",
    "    df_missing_tic_previous_value = df_before_date[previous_value_of_missing_tic_binary]\n",
    "    if df_missing_tic_previous_value.empty:\n",
    "        return None\n",
    "    else:\n",
    "        return df_missing_tic_previous_value.iloc[0]\n",
    "\n",
    "\n",
    "def fill_missed_tic_gaps(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    grouped_by_df = data_processor.dataframe.groupby(by=[\"date\"])\n",
    "    grouped_by_size = grouped_by_df.size()\n",
    "    max_size = grouped_by_size.max()\n",
    "    # print(grouped_by_size.unique())\n",
    "\n",
    "    for date in grouped_by_size[grouped_by_size < max_size].index:  # for each date where some tics are missed\n",
    "        ##\n",
    "        # print(date)\n",
    "        tics = get_missing_tic(df, date)\n",
    "        # print(tics)\n",
    "\n",
    "        for tic in tics:\n",
    "            filled_value = get_previous_value(df, date, missing_tic=tic)\n",
    "            filled_value = filled_value if filled_value is not None else get_following_value(df, date, missing_tic=tic)\n",
    "            if filled_value is None:\n",
    "                raise ValueError(\"None value of filling value\")\n",
    "            else:\n",
    "                filled_value[\"date\"] = date\n",
    "                df = df.append(filled_value)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_difference_in_timeframe():\n",
    "    grouped_by_df = df_filled_gaps.groupby(by=[\"date\"])\n",
    "    grouped_by_size = grouped_by_df.size()\n",
    "    return grouped_by_size\n",
    "\n",
    "\n",
    "df_filled_gaps = fill_missed_tic_gaps(data_processor.dataframe)\n",
    "print(get_difference_in_timeframe().unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "data": {
      "text/plain": "80917"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _d = df['date'] <= '2011-01-04'\n",
    "# prtin(_d == True).sum()\n",
    "# prtin(_d == False).sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6]\n",
      "3\n",
      "Int64Index([3, 4], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([5, 5, 5, 6, 6])\n",
    "\n",
    "u = s.unique()\n",
    "print(u)\n",
    "c = (s == u[0]).sum()\n",
    "print(c)\n",
    "idxs = s.index[s.isin([u[1]])]\n",
    "print(idxs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "\n",
    "for tic in tickers:\n",
    "    temp_df = yf.download(\n",
    "        tic,\n",
    "        start=_TRAIN_DATA_START,\n",
    "        end=_TEST_DATA_END,\n",
    "        interval=\"1d\",\n",
    "    )\n",
    "    temp_df[\"tic\"] = tic\n",
    "    dataframe = pd.concat([dataframe, temp_df], axis=0, join=\"outer\")\n",
    "dataframe.reset_index(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = data_processor.get_filename(prj_dir=prj_dir, name=\"dji30_ta\")\n",
    "check_dir(filename)\n",
    "\n",
    "# %load_ext line_profiler\n",
    "# %lprun -f save_dataset save_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "save_dataset(dataframe=data_processor.dataframe, type=FileType.JSON, filename)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_processor.dataframe.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fe = FeatureEngineer(use_technical_indicator=True, use_turbulence=False, user_defined_feature=False)\n",
    "data_features: pd.DataFrame = fe.preprocess_data(data_processor.dataframe.copy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_features.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data into: /Users/zlapik/my-drive-zlapik/0-todo/ai-investing/dataset/stock/ai4finance/dji30_ta_2022-12-14T20-13-55.json\n",
      "Data saved to json: /Users/zlapik/my-drive-zlapik/0-todo/ai-investing/dataset/stock/ai4finance/dji30_ta_2022-12-14T20-13-55.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dataset(dataframe=data_processor.dataframe, type=FileType.JSON, filename)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [11], line 28\u001B[0m\n\u001B[1;32m     24\u001B[0m     df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39msort_values([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtic\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m---> 28\u001B[0m data_features_cov1 \u001B[38;5;241m=\u001B[39m add_cov(\u001B[43mdata_features\u001B[49m\u001B[38;5;241m.\u001B[39mcopy())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_features' is not defined"
     ]
    }
   ],
   "source": [
    "def add_cov(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ##\n",
    "    # add covariance matrix as states\n",
    "    df = df.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "    df.index = df.date.factorize()[0]\n",
    "\n",
    "    cov_list = []\n",
    "    return_list = []\n",
    "\n",
    "    # look back is one year\n",
    "    lookback = 252\n",
    "    for i in tqdm.tqdm(range(lookback, len(df.index.unique()))):\n",
    "        data_lookback = df.loc[i - lookback : i, :]\n",
    "        price_lookback = data_lookback.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "        return_lookback = price_lookback.pct_change().dropna()\n",
    "        covs = return_lookback.cov().values\n",
    "\n",
    "        #\n",
    "        return_list.append(return_lookback)\n",
    "        cov_list.append(covs)\n",
    "\n",
    "    df_cov = pd.DataFrame({\"date\": df.date.unique()[lookback:], \"cov_list\": cov_list, \"return_list\": return_list})\n",
    "    df = df.merge(df_cov, on=\"date\")\n",
    "    df = df.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "data_features_cov1 = add_cov(data_features.copy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_features_cov1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdata_features_cov1\u001B[49m\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_features_cov1' is not defined"
     ]
    }
   ],
   "source": [
    "print(data_features_cov1.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# _df = data_features.copy()\n",
    "\n",
    "# rolling_window =\n",
    "# cov_matrix = _df.rolling(window=252).cov()\n",
    "\n",
    "# print(rolling_window)\n",
    "# print(_df.shape)\n",
    "\n",
    "# data_features_cov2 = cov2(data_features.copy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# print(data_features_cov2.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape=(0, 0)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [37], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mprint_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_processor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataframe\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [36], line 4\u001B[0m, in \u001B[0;36mprint_info\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprint_info\u001B[39m(df: pd\u001B[38;5;241m.\u001B[39mDataFrame):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m##\u001B[39;00m\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStart date: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnd date: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStocks: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtic\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique()\u001B[38;5;241m.\u001B[39msize\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3804\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3805\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3807\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'date'"
     ]
    }
   ],
   "source": [
    "print_info(data_processor.dataframe)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "         date       open       high        low      close  adjusted_close  \\\n0  2011-01-03  11.630000  11.795000  11.601429  11.770357       10.033262   \n1  2011-01-03  55.200001  56.279999  55.180000  55.549999       41.640541   \n2  2011-01-03  43.299999  43.619999  43.110001  43.400002       36.488426   \n3  2011-01-03  66.150002  66.680000  66.000000  66.400002       53.034523   \n4  2011-01-03  94.379997  94.809998  94.110001  94.150002       68.190575   \n\n      volume   tic  day      macd    boll_ub    boll_lb     rsi_30  \\\n0  445138400  AAPL    0  0.118248  11.709899  11.326780  62.862180   \n1    5453300  AMGN    0  0.261720  58.568809  52.495191  50.863117   \n2    7633300   AXP    0 -0.178628  47.098241  41.260759  51.443736   \n3    8072900    BA    0 -0.081580  66.520526  63.197475  51.659856   \n4    5231500   CAT    0  2.266966  96.271975  88.886025  68.687627   \n\n       cci_30      dx_30  close_30_sma  close_60_sma  \\\n0  144.286559  25.488753     11.415357     11.212333   \n1   34.401812   4.927279     54.949000     55.565166   \n2  -26.423899  13.049417     43.883000     42.473000   \n3  149.651676  11.924376     64.853001     66.948501   \n4   82.330220  50.929600     90.157333     85.266833   \n\n                                            cov_list  \\\n0  [[0.0002849618759954093, 9.196035527740299e-05...   \n1  [[0.0002849618759954093, 9.196035527740299e-05...   \n2  [[0.0002849618759954093, 9.196035527740299e-05...   \n3  [[0.0002849618759954093, 9.196035527740299e-05...   \n4  [[0.0002849618759954093, 9.196035527740299e-05...   \n\n                                         return_list  \n0  tic             AAPL      AMGN       AXP      ...  \n1  tic             AAPL      AMGN       AXP      ...  \n2  tic             AAPL      AMGN       AXP      ...  \n3  tic             AAPL      AMGN       AXP      ...  \n4  tic             AAPL      AMGN       AXP      ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adjusted_close</th>\n      <th>volume</th>\n      <th>tic</th>\n      <th>day</th>\n      <th>macd</th>\n      <th>boll_ub</th>\n      <th>boll_lb</th>\n      <th>rsi_30</th>\n      <th>cci_30</th>\n      <th>dx_30</th>\n      <th>close_30_sma</th>\n      <th>close_60_sma</th>\n      <th>cov_list</th>\n      <th>return_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-03</td>\n      <td>11.630000</td>\n      <td>11.795000</td>\n      <td>11.601429</td>\n      <td>11.770357</td>\n      <td>10.033262</td>\n      <td>445138400</td>\n      <td>AAPL</td>\n      <td>0</td>\n      <td>0.118248</td>\n      <td>11.709899</td>\n      <td>11.326780</td>\n      <td>62.862180</td>\n      <td>144.286559</td>\n      <td>25.488753</td>\n      <td>11.415357</td>\n      <td>11.212333</td>\n      <td>[[0.0002849618759954093, 9.196035527740299e-05...</td>\n      <td>tic             AAPL      AMGN       AXP      ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-03</td>\n      <td>55.200001</td>\n      <td>56.279999</td>\n      <td>55.180000</td>\n      <td>55.549999</td>\n      <td>41.640541</td>\n      <td>5453300</td>\n      <td>AMGN</td>\n      <td>0</td>\n      <td>0.261720</td>\n      <td>58.568809</td>\n      <td>52.495191</td>\n      <td>50.863117</td>\n      <td>34.401812</td>\n      <td>4.927279</td>\n      <td>54.949000</td>\n      <td>55.565166</td>\n      <td>[[0.0002849618759954093, 9.196035527740299e-05...</td>\n      <td>tic             AAPL      AMGN       AXP      ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-03</td>\n      <td>43.299999</td>\n      <td>43.619999</td>\n      <td>43.110001</td>\n      <td>43.400002</td>\n      <td>36.488426</td>\n      <td>7633300</td>\n      <td>AXP</td>\n      <td>0</td>\n      <td>-0.178628</td>\n      <td>47.098241</td>\n      <td>41.260759</td>\n      <td>51.443736</td>\n      <td>-26.423899</td>\n      <td>13.049417</td>\n      <td>43.883000</td>\n      <td>42.473000</td>\n      <td>[[0.0002849618759954093, 9.196035527740299e-05...</td>\n      <td>tic             AAPL      AMGN       AXP      ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-01-03</td>\n      <td>66.150002</td>\n      <td>66.680000</td>\n      <td>66.000000</td>\n      <td>66.400002</td>\n      <td>53.034523</td>\n      <td>8072900</td>\n      <td>BA</td>\n      <td>0</td>\n      <td>-0.081580</td>\n      <td>66.520526</td>\n      <td>63.197475</td>\n      <td>51.659856</td>\n      <td>149.651676</td>\n      <td>11.924376</td>\n      <td>64.853001</td>\n      <td>66.948501</td>\n      <td>[[0.0002849618759954093, 9.196035527740299e-05...</td>\n      <td>tic             AAPL      AMGN       AXP      ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-01-03</td>\n      <td>94.379997</td>\n      <td>94.809998</td>\n      <td>94.110001</td>\n      <td>94.150002</td>\n      <td>68.190575</td>\n      <td>5231500</td>\n      <td>CAT</td>\n      <td>0</td>\n      <td>2.266966</td>\n      <td>96.271975</td>\n      <td>88.886025</td>\n      <td>68.687627</td>\n      <td>82.330220</td>\n      <td>50.929600</td>\n      <td>90.157333</td>\n      <td>85.266833</td>\n      <td>[[0.0002849618759954093, 9.196035527740299e-05...</td>\n      <td>tic             AAPL      AMGN       AXP      ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features_cov1.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_features_cov1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [15], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m _d \u001B[38;5;241m=\u001B[39m \u001B[43mdata_features_cov1\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcov_list\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      2\u001B[0m _d\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_features_cov1' is not defined"
     ]
    }
   ],
   "source": [
    "_d = data_features_cov1[\"cov_list\"][0]\n",
    "_d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data into: /Users/zlapik/my-drive-zlapik/0-todo/ai-investing/dataset/stock/ai4finance/dji30_ta_2022-12-14T20-13-55.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [20], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# check_dir()\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[43msave_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_features_cov1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mFileType\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mJSON\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# df_json = pd.read_json(filename, orient=\"split\")\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# df_json.head()\u001B[39;00m\n",
      "Cell \u001B[0;32mIn [9], line 17\u001B[0m, in \u001B[0;36msave_dataset\u001B[0;34m(dataframe, type)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSaving data into: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m \u001B[38;5;241m==\u001B[39m FileType\u001B[38;5;241m.\u001B[39mJSON:\n\u001B[0;32m---> 17\u001B[0m     \u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m \u001B[38;5;241m==\u001B[39m FileType\u001B[38;5;241m.\u001B[39mCSV:\n\u001B[1;32m     19\u001B[0m     dataframe\u001B[38;5;241m.\u001B[39mto_csv(filename)\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/generic.py:2650\u001B[0m, in \u001B[0;36mNDFrame.to_json\u001B[0;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001B[0m\n\u001B[1;32m   2647\u001B[0m config\u001B[38;5;241m.\u001B[39mis_nonnegative_int(indent)\n\u001B[1;32m   2648\u001B[0m indent \u001B[38;5;241m=\u001B[39m indent \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 2650\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_json\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2651\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2652\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2653\u001B[0m \u001B[43m    \u001B[49m\u001B[43morient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2654\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2655\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdouble_precision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdouble_precision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2656\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_ascii\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_ascii\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2657\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_unit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2658\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdefault_handler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2659\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlines\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2660\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2661\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2662\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2663\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2664\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/io/json/_json.py:171\u001B[0m, in \u001B[0;36mto_json\u001B[0;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobj\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m should be a Series or a DataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    161\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[43mwriter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m    \u001B[49m\u001B[43morient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdouble_precision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdouble_precision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_ascii\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_ascii\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_unit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdefault_handler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m--> 171\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lines:\n\u001B[1;32m    174\u001B[0m     s \u001B[38;5;241m=\u001B[39m convert_to_line_delimits(s)\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/io/json/_json.py:224\u001B[0m, in \u001B[0;36mWriter.write\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrite\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m    223\u001B[0m     iso_dates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdate_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdumps\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj_to_write\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m        \u001B[49m\u001B[43morient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdouble_precision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdouble_precision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    228\u001B[0m \u001B[43m        \u001B[49m\u001B[43mensure_ascii\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mensure_ascii\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    229\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdate_unit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdate_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[43m        \u001B[49m\u001B[43miso_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miso_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdefault_handler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdefault_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    233\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/frame.py:11661\u001B[0m, in \u001B[0;36mDataFrame.values\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m  11655\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m cast(BlockManager, mgr)\n\u001B[1;32m  11656\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m  11657\u001B[0m         k: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(v)\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m  11658\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, v, \u001B[38;5;129;01min\u001B[39;00m mgr\u001B[38;5;241m.\u001B[39mto_dict(copy\u001B[38;5;241m=\u001B[39mcopy)\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m  11659\u001B[0m     }\n\u001B[0;32m> 11661\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m  11662\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalues\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m  11663\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m  11664\u001B[0m \u001B[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001B[39;00m\n\u001B[1;32m  11665\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m  11733\u001B[0m \u001B[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001B[39;00m\n\u001B[1;32m  11734\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m  11735\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consolidate_inplace()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# check_dir()\n",
    "\n",
    "save_dataset(dataframe=data_features_cov1, type=FileType.JSON, filename)\n",
    "\n",
    "# df_json = pd.read_json(filename, orient=\"split\")\n",
    "# df_json.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_gDkU-j-fCmZ",
    "MRiOtrywfAo1",
    "3Zpv4S0-fDBv",
    "Dr49PotrfG01"
   ],
   "name": "Stock_Fundamental.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv3.10': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "32c0c8ab8a6b580687c5ec847b855eb3ee7063ee446f183d34922604f3e580fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
