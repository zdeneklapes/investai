{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _DATATYPE = _descriptor.EnumDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORPROTO = _descriptor.Descriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/summary_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/summary_pb2.py:35: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/summary_pb2.py:29: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _DATACLASS = _descriptor.EnumDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/summary_pb2.py:74: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/tensorboard/compat/proto/summary_pb2.py:67: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _SUMMARYDESCRIPTION = _descriptor.Descriptor(\n",
      "/Users/zlapik/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import enum\n",
    "from enum import Enum\n",
    "import matplotlib\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "##\n",
    "sys.path.append(\"./src/\")\n",
    "sys.path.append(\"./\")\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "##\n",
    "from finrl import config as finrl_config\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
    "from finrl.config import (\n",
    "    TEST_END_DATE,\n",
    "    TRAINED_MODEL_DIR,\n",
    ")\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "from finrl.plot import backtest_stats, convert_daily_return_to_pyfolio_ts, get_baseline\n",
    "\n",
    "##\n",
    "import yfinance as yf\n",
    "\n",
    "##\n",
    "from meta.data_processors.yahoofinance import Yahoofinance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def config():\n",
    "    # #\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)  # TODO: zipline problem\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    # os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # INFO, WARN are ignored and only ERROR messages will be printed\n",
    "\n",
    "    # #\n",
    "    matplotlib.use(\"Agg\")\n",
    "\n",
    "    # #\n",
    "    check_and_make_directories(\n",
    "        [\n",
    "            finrl_config.DATA_SAVE_DIR,\n",
    "            finrl_config.TRAINED_MODEL_DIR,\n",
    "            finrl_config.TENSORBOARD_LOG_DIR,\n",
    "            finrl_config.RESULTS_DIR,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "config()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "##\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyfolio import timeseries\n",
    "import tqdm\n",
    "\n",
    "##\n",
    "from rl.data import DataTechnicalAnalysis, DataFundamentalAnalysis, DataBase\n",
    "from common.utils import now_time\n",
    "from configuration.settings import ProjectDir"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def print_info(df: pd.DataFrame):\n",
    "    ##\n",
    "    print(f\"{df.shape=}\")\n",
    "    print(f\"Start date: {df['date'].iloc[0]}\")\n",
    "    print(f\"End date: {df['date'].iloc[-1]}\")\n",
    "    print(f\"Stocks: {df['tic'].unique().size}\")\n",
    "\n",
    "    ##\n",
    "    data_grouped_by_date = df.groupby(by=[\"date\"])\n",
    "    grouped_data_size = data_grouped_by_date.size()\n",
    "    if grouped_data_size.nunique() == 1:\n",
    "        print(f\"OK: All dates have same row count: {grouped_data_size.unique()}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Different size for each date: {grouped_data_size.unique()}\")\n",
    "\n",
    "\n",
    "def check_dir(_filename: Path):\n",
    "    dir = _filename.parent\n",
    "    if os.path.isdir(dir):\n",
    "        print(f\"OK: Dir exist for: {_filename}\")\n",
    "    else:\n",
    "        raise NotADirectoryError(f\"ERROR: Dir does not exist {dir}\")\n",
    "\n",
    "\n",
    "class FileType(Enum):\n",
    "    JSON = enum.auto\n",
    "    CSV = enum.auto\n",
    "\n",
    "\n",
    "def save_dataset(dataframe: pd.DataFrame, type: FileType, _filename: Path):\n",
    "    print(f\"Saving data into: {_filename}\")\n",
    "    if type == FileType.JSON:\n",
    "        dataframe.to_json(_filename.as_posix())\n",
    "    elif type == FileType.CSV:\n",
    "        dataframe.to_csv(_filename)\n",
    "    else:\n",
    "        raise ValueError(f\"type: FileType must be CSV or JSON.\")\n",
    "    print(f\"Data saved to json: {_filename}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "prj_dir = ProjectDir(root=Path(\"/Users/zlapik/my-drive-zlapik/0-todo/ai-investing\"))\n",
    "_TRAIN_DATA_START = \"2010-01-01\"\n",
    "_TRAIN_DATA_END = \"2021-12-31\"\n",
    "_TEST_DATA_START = \"2021-01-01\"\n",
    "_TEST_DATA_END = \"2021-12-31\"\n",
    "tickers = DOW_30_TICKER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
     ]
    }
   ],
   "source": [
    "print(tickers.__len__())\n",
    "print(tickers)\n",
    "data_processor = DataBase(\n",
    "    data_source=\"yahoofinance\", start_date=_TRAIN_DATA_START, end_date=_TEST_DATA_END, time_interval=\"1d\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (88283, 9)\n"
     ]
    }
   ],
   "source": [
    "data_processor.download_data(ticker_list=tickers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88283, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": "         date       open       high        low      close  adjusted_close  \\\n0  2010-01-04   7.622500   7.660714   7.585000   7.643214        6.515213   \n1  2010-01-04  56.630001  57.869999  56.560001  57.720001       43.267181   \n2  2010-01-04  40.810001  41.099998  40.389999  40.919998       33.792698   \n3  2010-01-04  55.720001  56.389999  54.799999  56.180000       43.777550   \n4  2010-01-04  57.650002  59.189999  57.509998  58.549999       41.353191   \n\n      volume   tic  day  \n0  493729600  AAPL    0  \n1    5277400  AMGN    0  \n2    6894300   AXP    0  \n3    6186700    BA    0  \n4    7325600   CAT    0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adjusted_close</th>\n      <th>volume</th>\n      <th>tic</th>\n      <th>day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-01-04</td>\n      <td>7.622500</td>\n      <td>7.660714</td>\n      <td>7.585000</td>\n      <td>7.643214</td>\n      <td>6.515213</td>\n      <td>493729600</td>\n      <td>AAPL</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-01-04</td>\n      <td>56.630001</td>\n      <td>57.869999</td>\n      <td>56.560001</td>\n      <td>57.720001</td>\n      <td>43.267181</td>\n      <td>5277400</td>\n      <td>AMGN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-01-04</td>\n      <td>40.810001</td>\n      <td>41.099998</td>\n      <td>40.389999</td>\n      <td>40.919998</td>\n      <td>33.792698</td>\n      <td>6894300</td>\n      <td>AXP</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-01-04</td>\n      <td>55.720001</td>\n      <td>56.389999</td>\n      <td>54.799999</td>\n      <td>56.180000</td>\n      <td>43.777550</td>\n      <td>6186700</td>\n      <td>BA</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-01-04</td>\n      <td>57.650002</td>\n      <td>59.189999</td>\n      <td>57.509998</td>\n      <td>58.549999</td>\n      <td>41.353191</td>\n      <td>7325600</td>\n      <td>CAT</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_processor.dataframe.shape)\n",
    "data_processor.dataframe.head()\n",
    "# print_info(data_processor.dataframe)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 : 2317\n",
      "30 : 703\n"
     ]
    }
   ],
   "source": [
    "def get_missing_counts(df: pd.DataFrame):\n",
    "    grouped_by_df = df.groupby(by=[\"date\"])\n",
    "    grouped_by_size = grouped_by_df.size()\n",
    "    counts = pd.Series([])\n",
    "    for i in grouped_by_size.unique():\n",
    "        occurences = (grouped_by_size == i).sum()\n",
    "        counts = counts.append(pd.Series(occurences))\n",
    "        print(f\"{i} : {occurences}\")\n",
    "\n",
    "\n",
    "get_missing_counts(data_processor.dataframe)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2317/2317 [00:52<00:00, 44.31it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_missing_tic(df: pd.DataFrame, date: str) -> list:\n",
    "    df_date = df[df[\"date\"] == date]\n",
    "    missing_tics: set = set(tickers).difference(set(df_date[\"tic\"].values))\n",
    "    missing_tics: list = list(missing_tics)\n",
    "    return [missing_tics]\n",
    "\n",
    "\n",
    "def get_previous_value(df: pd.DataFrame, date: str, missing_tic: str):\n",
    "    df_before_date_binary = df[\"date\"] < date\n",
    "    df_before_date = df[df_before_date_binary]\n",
    "    previous_value_of_missing_tic = df_before_date[\"tic\"] == missing_tic[0]\n",
    "    df_missing_tic_previous_value = df_before_date[previous_value_of_missing_tic]\n",
    "    if df_missing_tic_previous_value.empty:\n",
    "        return None\n",
    "    else:\n",
    "        return df_missing_tic_previous_value.iloc[-1]\n",
    "\n",
    "\n",
    "def get_following_value(df: pd.DataFrame, date: str, missing_tic: str):\n",
    "    df_before_date_binary = df[\"date\"] > date\n",
    "    df_before_date = df[df_before_date_binary]\n",
    "    previous_value_of_missing_tic_binary = df_before_date[\"tic\"] == missing_tic[0]\n",
    "    df_missing_tic_previous_value = df_before_date[previous_value_of_missing_tic_binary]\n",
    "    if df_missing_tic_previous_value.empty:\n",
    "        return None\n",
    "    else:\n",
    "        return df_missing_tic_previous_value.iloc[0]\n",
    "\n",
    "\n",
    "def fill_missed_tic_gaps(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    grouped_by_df = data_processor.dataframe.groupby(by=[\"date\"])\n",
    "    grouped_by_size = grouped_by_df.size()\n",
    "    max_size = grouped_by_size.max()\n",
    "    # print(grouped_by_size.unique())\n",
    "\n",
    "    for date in tqdm.tqdm(\n",
    "        grouped_by_size[grouped_by_size < max_size].index\n",
    "    ):  # for each date where some tics are missed\n",
    "        ##\n",
    "        tics = get_missing_tic(df, date)  # TODO: Improve performance 1/3 time is here\n",
    "\n",
    "        ##\n",
    "        for tic in tics:\n",
    "            ##\n",
    "            filled_value = get_previous_value(df, date, missing_tic=tic)  # TODO: Improve performance 1/3 time is here\n",
    "            filled_value = filled_value if filled_value is not None else get_following_value(df, date, missing_tic=tic)\n",
    "\n",
    "            ##\n",
    "            if filled_value is None:\n",
    "                raise ValueError(\"None value of filling value\")\n",
    "            else:\n",
    "                filled_value[\"date\"] = date  # update date we want to fill the gap\n",
    "                df = df.append(filled_value)  # TODO: Improve performance 1/3 time is here\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_difference_in_timeframe(df: pd.DataFrame):\n",
    "    grouped_by_df = df.groupby(by=[\"date\"])\n",
    "    grouped_by_size = grouped_by_df.size()\n",
    "    return grouped_by_size\n",
    "\n",
    "\n",
    "# % load_ext line_profiler\n",
    "\n",
    "# % lprun -f fill_missed_tic_gaps df_filled_gaps = fill_missed_tic_gaps(data_processor.dataframe)\n",
    "\n",
    "df_filled_gaps = fill_missed_tic_gaps(data_processor.dataframe)\n",
    "# print(get_difference_in_timeframe(df_filled_gaps).unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: Dir exist for: /Users/zlapik/my-drive-zlapik/0-todo/ai-investing/dataset/stock/ai4finance/dji30_ta_2022-12-15T02-08-46.json\n"
     ]
    }
   ],
   "source": [
    "filename = data_processor.get_filename(prj_dir=prj_dir, name=\"dji30_ta\")\n",
    "check_dir(filename)\n",
    "\n",
    "# %load_ext line_profiler\n",
    "# %lprun -f save_dataset save_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(90600, 9)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled_gaps.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(use_technical_indicator=True, use_turbulence=False, user_defined_feature=False)\n",
    "data_features: pd.DataFrame = fe.preprocess_data(df_filled_gaps.copy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "data_features = data_features.sort_values([\"date\", \"tic\"]).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(90600, 17)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data into: /Users/zlapik/my-drive-zlapik/0-todo/ai-investing/dataset/stock/ai4finance/dji30_ta_2022-12-15T02-08-46.json\n",
      "Data saved to json: /Users/zlapik/my-drive-zlapik/0-todo/ai-investing/dataset/stock/ai4finance/dji30_ta_2022-12-15T02-08-46.json\n"
     ]
    }
   ],
   "source": [
    "save_dataset(dataframe=data_features, type=FileType.JSON, _filename=filename)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2768 [08:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [52], line 27\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;66;03m# df[\"covariance_matrix\"] = df_cov\u001B[39;00m\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;66;03m# df = df.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\u001B[39;00m\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df_cov\n\u001B[0;32m---> 27\u001B[0m df_cov \u001B[38;5;241m=\u001B[39m \u001B[43madd_covariance_as_nested_states\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_features\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# TODO: merge to dataset\u001B[39;00m\n",
      "Cell \u001B[0;32mIn [52], line 14\u001B[0m, in \u001B[0;36madd_covariance_as_nested_states\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m     12\u001B[0m data_lookback \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mloc[i \u001B[38;5;241m-\u001B[39m lookback: i, :]\n\u001B[1;32m     13\u001B[0m price_lookback \u001B[38;5;241m=\u001B[39m data_lookback\u001B[38;5;241m.\u001B[39mpivot_table(index\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m\"\u001B[39m, columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtic\u001B[39m\u001B[38;5;124m\"\u001B[39m, values\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclose\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 14\u001B[0m return_lookback \u001B[38;5;241m=\u001B[39m \u001B[43mprice_lookback\u001B[49m\u001B[38;5;241m.\u001B[39mpct_change()\u001B[38;5;241m.\u001B[39mdropna()\n\u001B[1;32m     15\u001B[0m covs \u001B[38;5;241m=\u001B[39m return_lookback\u001B[38;5;241m.\u001B[39mcov()\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n",
      "Cell \u001B[0;32mIn [52], line 14\u001B[0m, in \u001B[0;36madd_covariance_as_nested_states\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m     12\u001B[0m data_lookback \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mloc[i \u001B[38;5;241m-\u001B[39m lookback: i, :]\n\u001B[1;32m     13\u001B[0m price_lookback \u001B[38;5;241m=\u001B[39m data_lookback\u001B[38;5;241m.\u001B[39mpivot_table(index\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m\"\u001B[39m, columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtic\u001B[39m\u001B[38;5;124m\"\u001B[39m, values\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclose\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 14\u001B[0m return_lookback \u001B[38;5;241m=\u001B[39m \u001B[43mprice_lookback\u001B[49m\u001B[38;5;241m.\u001B[39mpct_change()\u001B[38;5;241m.\u001B[39mdropna()\n\u001B[1;32m     15\u001B[0m covs \u001B[38;5;241m=\u001B[39m return_lookback\u001B[38;5;241m.\u001B[39mcov()\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1053\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/PyCharm-P/ch-0/223.7571.203/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[1;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[0;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/PyCharm-P/ch-0/223.7571.203/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/PyCharm-P/ch-0/223.7571.203/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def add_covariance_as_nested_states(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ##\n",
    "    df = df.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "    df.index = df.date.factorize()[0]\n",
    "\n",
    "    cov_list = []\n",
    "    return_list = []\n",
    "\n",
    "    # look back is one year\n",
    "    lookback = 252\n",
    "    for i in tqdm.tqdm(range(lookback, len(df.index.unique()))):\n",
    "        data_lookback = df.loc[i - lookback : i, :]\n",
    "        price_lookback = data_lookback.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "        return_lookback = price_lookback.pct_change().dropna()\n",
    "        covs = return_lookback.cov().values\n",
    "\n",
    "        #\n",
    "        return_list.append(return_lookback)\n",
    "        cov_list.append(covs)\n",
    "\n",
    "    df_cov = pd.DataFrame({\"date\": df.date.unique()[lookback:], \"cov_list\": cov_list, \"return_list\": return_list})\n",
    "    # df[\"covariance_matrix\"] = df_cov\n",
    "    # df = df.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n",
    "    return df_cov\n",
    "\n",
    "\n",
    "# TODO: fixme add covariance as states\n",
    "df_cov = add_covariance_as_nested_states(data_features.copy())\n",
    "# TODO: merge to dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2768, 3)\n",
      "(2768,)\n",
      "(2768,)\n"
     ]
    }
   ],
   "source": [
    "# print(df_cov.shape)\n",
    "# print(df_cov['cov_list'].shape)\n",
    "# print(df_cov['return_list'].shape)\n",
    "\n",
    "# df_cov['cov_list'] = df_cov['cov_list'].apply(lambda x: pd.DataFrame(x))\n",
    "# df_cov['cov_list']\n",
    "# _d3 = pd.DataFrame(df_cov['cov_list'][0])\n",
    "# _d4 = df_cov['cov_list']\n",
    "# _d3 = pd.DataFrame(df_cov['return_list'][0])\n",
    "# _d4 = df_cov['return_list'][0]\n",
    "# df_cov['return_list']\n",
    "# _d1 = df_cov['cov_list']\n",
    "# _d2 = df_cov['return_list']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "df_cov.to_json(\"foo.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0       [[0.0002849618759954093, 9.196035527740299e-05...\n1       [[0.0002850066689925423, 9.224443498717904e-05...\n2       [[0.0002838971487853813, 9.16941940901012e-05,...\n3       [[0.0002838698218188037, 9.158961530444638e-05...\n4       [[0.00028388999474777423, 9.158103382271378e-0...\n                              ...                        \n2763    [[0.00025416445352502334, 4.899979240800397e-0...\n2764    [[0.00025586787418637315, 4.9525971145642e-05,...\n2765    [[0.0002513291755320819, 4.902713173926194e-05...\n2766    [[0.00025048848339192836, 4.9832109315140924e-...\n2767    [[0.0002503516522709732, 5.0038111289378386e-0...\nName: cov_list, Length: 2768, dtype: object"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_cov1 = pd.DataFrame({\"cov_list\":})\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  4\n",
      "4  5\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "You can only assign a scalar value not a <class 'pandas.core.frame.DataFrame'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:144\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'slice(None, None, None)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/frame.py:4208\u001B[0m, in \u001B[0;36mDataFrame._set_value\u001B[0;34m(self, index, col, value, takeable)\u001B[0m\n\u001B[1;32m   4207\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4208\u001B[0m     icol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4209\u001B[0m     iindex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mget_loc(index)\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3810\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m-> 3810\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_indexing_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3811\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:5968\u001B[0m, in \u001B[0;36mIndex._check_indexing_error\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   5965\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(key):\n\u001B[1;32m   5966\u001B[0m     \u001B[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001B[39;00m\n\u001B[1;32m   5967\u001B[0m     \u001B[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001B[39;00m\n\u001B[0;32m-> 5968\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m: slice(None, None, None)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [30], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m:[\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m5\u001B[39m]})\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Put the dataframe into a cell in the empty dataframe\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mat\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Print the resulting dataframe\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(df)\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/indexing.py:2442\u001B[0m, in \u001B[0;36m_AtIndexer.__setitem__\u001B[0;34m(self, key, value)\u001B[0m\n\u001B[1;32m   2439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39mloc[key] \u001B[38;5;241m=\u001B[39m value\n\u001B[1;32m   2440\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m-> 2442\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__setitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/indexing.py:2397\u001B[0m, in \u001B[0;36m_ScalarAccessIndexer.__setitem__\u001B[0;34m(self, key, value)\u001B[0m\n\u001B[1;32m   2394\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(key) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mndim:\n\u001B[1;32m   2395\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNot enough indexers for scalar access (setting)!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 2397\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_value\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtakeable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_takeable\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/frame.py:4227\u001B[0m, in \u001B[0;36mDataFrame._set_value\u001B[0;34m(self, index, col, value, takeable)\u001B[0m\n\u001B[1;32m   4222\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_item_cache\u001B[38;5;241m.\u001B[39mpop(col, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   4224\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidIndexError \u001B[38;5;28;01mas\u001B[39;00m ii_err:\n\u001B[1;32m   4225\u001B[0m     \u001B[38;5;66;03m# GH48729: Seems like you are trying to assign a value to a\u001B[39;00m\n\u001B[1;32m   4226\u001B[0m     \u001B[38;5;66;03m# row when only scalar options are permitted\u001B[39;00m\n\u001B[0;32m-> 4227\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(\n\u001B[1;32m   4228\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can only assign a scalar value not a \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(value)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4229\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mii_err\u001B[39;00m\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m: You can only assign a scalar value not a <class 'pandas.core.frame.DataFrame'>"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with some data\n",
    "data = pd.DataFrame([1, 2, 3, 4, 5])\n",
    "print(data)\n",
    "\n",
    "# Create an empty dataframe\n",
    "df = pd.DataFrame({\"a\": [5, 5, 5, 5, 5]})\n",
    "\n",
    "# Put the dataframe into a cell in the empty dataframe\n",
    "df.at[0] = data\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# _df = data_features.copy()\n",
    "\n",
    "# rolling_window =\n",
    "# cov_matrix = _df.rolling(window=252).cov()\n",
    "\n",
    "# print(rolling_window)\n",
    "# print(_df.shape)\n",
    "\n",
    "# data_features_cov2 = cov2(data_features.copy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# print(data_features_cov2.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape=(0, 0)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [37], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mprint_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_processor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataframe\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [36], line 4\u001B[0m, in \u001B[0;36mprint_info\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprint_info\u001B[39m(df: pd\u001B[38;5;241m.\u001B[39mDataFrame):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m##\u001B[39;00m\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStart date: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnd date: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStocks: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtic\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique()\u001B[38;5;241m.\u001B[39msize\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3804\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3805\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3807\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'date'"
     ]
    }
   ],
   "source": [
    "print_info(data_processor.dataframe)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "         date       open       high        low      close  adjusted_close  \\\n0  2011-01-03  11.630000  11.795000  11.601429  11.770357       10.033262   \n1  2011-01-03  55.200001  56.279999  55.180000  55.549999       41.640541   \n2  2011-01-03  43.299999  43.619999  43.110001  43.400002       36.488426   \n3  2011-01-03  66.150002  66.680000  66.000000  66.400002       53.034523   \n4  2011-01-03  94.379997  94.809998  94.110001  94.150002       68.190575   \n\n      volume   tic  day      macd    boll_ub    boll_lb     rsi_30  \\\n0  445138400  AAPL    0  0.118248  11.709899  11.326780  62.862180   \n1    5453300  AMGN    0  0.261720  58.568809  52.495191  50.863117   \n2    7633300   AXP    0 -0.178628  47.098241  41.260759  51.443736   \n3    8072900    BA    0 -0.081580  66.520526  63.197475  51.659856   \n4    5231500   CAT    0  2.266966  96.271975  88.886025  68.687627   \n\n       cci_30      dx_30  close_30_sma  close_60_sma  \\\n0  144.286559  25.488753     11.415357     11.212333   \n1   34.401812   4.927279     54.949000     55.565166   \n2  -26.423899  13.049417     43.883000     42.473000   \n3  149.651676  11.924376     64.853001     66.948501   \n4   82.330220  50.929600     90.157333     85.266833   \n\n                                            cov_list  \\\n0  [[0.0002849618759954093, 9.196035527740299e-05...   \n1  [[0.0002849618759954093, 9.196035527740299e-05...   \n2  [[0.0002849618759954093, 9.196035527740299e-05...   \n3  [[0.0002849618759954093, 9.196035527740299e-05...   \n4  [[0.0002849618759954093, 9.196035527740299e-05...   \n\n                                         return_list  \n0  tic             AAPL      AMGN       AXP      ...  \n1  tic             AAPL      AMGN       AXP      ...  \n2  tic             AAPL      AMGN       AXP      ...  \n3  tic             AAPL      AMGN       AXP      ...  \n4  tic             AAPL      AMGN       AXP      ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adjusted_close</th>\n      <th>volume</th>\n      <th>tic</th>\n      <th>day</th>\n      <th>macd</th>\n      <th>boll_ub</th>\n      <th>boll_lb</th>\n      <th>rsi_30</th>\n      <th>cci_30</th>\n      <th>dx_30</th>\n      <th>close_30_sma</th>\n      <th>close_60_sma</th>\n      <th>cov_list</th>\n      <th>return_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-03</td>\n      <td>11.630000</td>\n      <td>11.795000</td>\n      <td>11.601429</td>\n      <td>11.770357</td>\n      <td>10.033262</td>\n      <td>445138400</td>\n      <td>AAPL</td>\n      <td>0</td>\n      <td>0.118248</td>\n      <td>11.709899</td>\n      <td>11.326780</td>\n      <td>62.862180</td>\n      <td>144.286559</td>\n      <td>25.488753</td>\n      <td>11.415357</td>\n      <td>11.212333</td>\n      <td>[[0.0002849618759954093, 9.196035527740299e-05...</td>\n      <td>tic             AAPL      AMGN       AXP      ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-03</td>\n      <td>55.200001</td>\n      <td>56.279999</td>\n      <td>55.180000</td>\n      <td>55.549999</td>\n      <td>41.640541</td>\n      <td>5453300</td>\n      <td>AMGN</td>\n      <td>0</td>\n      <td>0.261720</td>\n      <td>58.568809</td>\n      <td>52.495191</td>\n      <td>50.863117</td>\n      <td>34.401812</td>\n      <td>4.927279</td>\n      <td>54.949000</td>\n      <td>55.565166</td>\n      <td>[[0.0002849618759954093, 9.196035527740299e-05...</td>\n      <td>tic             AAPL      AMGN       AXP      ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-03</td>\n      <td>43.299999</td>\n      <td>43.619999</td>\n      <td>43.110001</td>\n      <td>43.400002</td>\n      <td>36.488426</td>\n      <td>7633300</td>\n      <td>AXP</td>\n      <td>0</td>\n      <td>-0.178628</td>\n      <td>47.098241</td>\n      <td>41.260759</td>\n      <td>51.443736</td>\n      <td>-26.423899</td>\n      <td>13.049417</td>\n      <td>43.883000</td>\n      <td>42.473000</td>\n      <td>[[0.0002849618759954093, 9.196035527740299e-05...</td>\n      <td>tic             AAPL      AMGN       AXP      ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-01-03</td>\n      <td>66.150002</td>\n      <td>66.680000</td>\n      <td>66.000000</td>\n      <td>66.400002</td>\n      <td>53.034523</td>\n      <td>8072900</td>\n      <td>BA</td>\n      <td>0</td>\n      <td>-0.081580</td>\n      <td>66.520526</td>\n      <td>63.197475</td>\n      <td>51.659856</td>\n      <td>149.651676</td>\n      <td>11.924376</td>\n      <td>64.853001</td>\n      <td>66.948501</td>\n      <td>[[0.0002849618759954093, 9.196035527740299e-05...</td>\n      <td>tic             AAPL      AMGN       AXP      ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-01-03</td>\n      <td>94.379997</td>\n      <td>94.809998</td>\n      <td>94.110001</td>\n      <td>94.150002</td>\n      <td>68.190575</td>\n      <td>5231500</td>\n      <td>CAT</td>\n      <td>0</td>\n      <td>2.266966</td>\n      <td>96.271975</td>\n      <td>88.886025</td>\n      <td>68.687627</td>\n      <td>82.330220</td>\n      <td>50.929600</td>\n      <td>90.157333</td>\n      <td>85.266833</td>\n      <td>[[0.0002849618759954093, 9.196035527740299e-05...</td>\n      <td>tic             AAPL      AMGN       AXP      ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features_cov1.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_features_cov1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [15], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m _d \u001B[38;5;241m=\u001B[39m \u001B[43mdata_features_cov1\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcov_list\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      2\u001B[0m _d\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_features_cov1' is not defined"
     ]
    }
   ],
   "source": [
    "_d = data_features_cov1[\"cov_list\"][0]\n",
    "_d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data into: /Users/zlapik/my-drive-zlapik/0-todo/ai-investing/dataset/stock/ai4finance/dji30_ta_2022-12-14T20-13-55.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [20], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# check_dir()\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[43msave_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_features_cov1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mFileType\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mJSON\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# df_json = pd.read_json(filename, orient=\"split\")\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# df_json.head()\u001B[39;00m\n",
      "Cell \u001B[0;32mIn [9], line 17\u001B[0m, in \u001B[0;36msave_dataset\u001B[0;34m(dataframe, type)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSaving data into: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m \u001B[38;5;241m==\u001B[39m FileType\u001B[38;5;241m.\u001B[39mJSON:\n\u001B[0;32m---> 17\u001B[0m     \u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m \u001B[38;5;241m==\u001B[39m FileType\u001B[38;5;241m.\u001B[39mCSV:\n\u001B[1;32m     19\u001B[0m     dataframe\u001B[38;5;241m.\u001B[39mto_csv(filename)\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/generic.py:2650\u001B[0m, in \u001B[0;36mNDFrame.to_json\u001B[0;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001B[0m\n\u001B[1;32m   2647\u001B[0m config\u001B[38;5;241m.\u001B[39mis_nonnegative_int(indent)\n\u001B[1;32m   2648\u001B[0m indent \u001B[38;5;241m=\u001B[39m indent \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 2650\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_json\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2651\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2652\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2653\u001B[0m \u001B[43m    \u001B[49m\u001B[43morient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2654\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2655\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdouble_precision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdouble_precision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2656\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_ascii\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_ascii\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2657\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_unit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2658\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdefault_handler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2659\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlines\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2660\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2661\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2662\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2663\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2664\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/io/json/_json.py:171\u001B[0m, in \u001B[0;36mto_json\u001B[0;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobj\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m should be a Series or a DataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    161\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[43mwriter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m    \u001B[49m\u001B[43morient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdouble_precision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdouble_precision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_ascii\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_ascii\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_unit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdefault_handler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m--> 171\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lines:\n\u001B[1;32m    174\u001B[0m     s \u001B[38;5;241m=\u001B[39m convert_to_line_delimits(s)\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/io/json/_json.py:224\u001B[0m, in \u001B[0;36mWriter.write\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrite\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m    223\u001B[0m     iso_dates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdate_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdumps\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj_to_write\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m        \u001B[49m\u001B[43morient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdouble_precision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdouble_precision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    228\u001B[0m \u001B[43m        \u001B[49m\u001B[43mensure_ascii\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mensure_ascii\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    229\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdate_unit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdate_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[43m        \u001B[49m\u001B[43miso_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miso_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdefault_handler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdefault_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    233\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my-drive-zlapik/0-todo/ai-investing/venv3.10/lib/python3.10/site-packages/pandas/core/frame.py:11661\u001B[0m, in \u001B[0;36mDataFrame.values\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m  11655\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m cast(BlockManager, mgr)\n\u001B[1;32m  11656\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m  11657\u001B[0m         k: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(v)\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m  11658\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, v, \u001B[38;5;129;01min\u001B[39;00m mgr\u001B[38;5;241m.\u001B[39mto_dict(copy\u001B[38;5;241m=\u001B[39mcopy)\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m  11659\u001B[0m     }\n\u001B[0;32m> 11661\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m  11662\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalues\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m  11663\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m  11664\u001B[0m \u001B[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001B[39;00m\n\u001B[1;32m  11665\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m  11733\u001B[0m \u001B[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001B[39;00m\n\u001B[1;32m  11734\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m  11735\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consolidate_inplace()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# check_dir()\n",
    "\n",
    "save_dataset(dataframe=data_features_cov1, type=FileType.JSON, filename)\n",
    "\n",
    "# df_json = pd.read_json(filename, orient=\"split\")\n",
    "# df_json.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_gDkU-j-fCmZ",
    "MRiOtrywfAo1",
    "3Zpv4S0-fDBv",
    "Dr49PotrfG01"
   ],
   "name": "Stock_Fundamental.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv3.10': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "32c0c8ab8a6b580687c5ec847b855eb3ee7063ee446f183d34922604f3e580fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
